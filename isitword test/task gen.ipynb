{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "thdf = pd.read_excel(\"word/th_wordlist - adjust.xlsx\")\n",
    "endf = pd.read_excel(\"word/en_wordlist.xlsx\")\n",
    "\n",
    "\n",
    "wordinfo = pd.concat([thdf, endf], ignore_index=True)\n",
    "wordinfo.to_excel(\"ref/dict.xlsx\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for both english word and thai word referring to their id --> len, word shown\n",
    "dic = pd.Series(thdf['word shown'],index=df.B).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create order list\n",
    "\n",
    "# define starting lang, 1 = th, 2 = en\n",
    "lang = [1,2]\n",
    "\n",
    "# define stimuli type, 1 = correct word, 2 = scramble, 3 = typo\n",
    "stimuli = [1,2,3]\n",
    "\n",
    "# word id, use the same as previous\n",
    "idth = thdf[\"Image ID\"].tolist()\n",
    "iden = endf[\"Image ID\"].tolist()\n",
    "\n",
    "wordorderth = pd.DataFrame([[1, n, p] for n in stimuli for p in idth], columns = [\"lang\", \"stimuli\", \"imageid\"])\n",
    "wordorderen = pd.DataFrame([[2, n, p] for n in stimuli for p in iden], columns = [\"lang\", \"stimuli\", \"imageid\"])\n",
    "wordorderfull = pd.concat([wordorderth, wordorderen], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(0, len(lang)):\n",
    "    for n in range(0, len(stimuli)):\n",
    "        wordorderfull.loc[120*m + 40*n:120*m + 40*(n+1)-1,\"word shown\"] = wordinfo.iloc[40*m:40*(m+1),n + 1].tolist()\n",
    "        wordorderfull.loc[120*m + 40*n:120*m + 40*(n+1)-1,\"word_length\"] = wordinfo.iloc[40*m:40*(m+1),4].tolist()\n",
    "checker = wordorderfull[\"word shown\"].duplicated()\n",
    "\n",
    "wordorderfull['worddir'] = wordorderfull.apply(\n",
    "    lambda row: f\"word/word{'th' if row['lang'] == 1 else 'en'}{row['imageid']:03}{row['stimuli']}.png\", axis=1\n",
    ")\n",
    "\n",
    "group = wordorderfull.groupby(wordorderfull.lang)\n",
    "wordorderth_full = group.get_group(1).reset_index(drop=True)\n",
    "wordorderen_full = group.get_group(2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rep_n_ran(df, dirref, dirrun):\n",
    "    randed = df.sample(frac = 1)\n",
    "    randed.to_excel(dirref, index=None)\n",
    "\n",
    "    order = randed.drop(columns=[\"word shown\"])\n",
    "    order.to_excel(dirrun, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_n_ran(wordorderth_full, \"ref/wordorderth_full2.xlsx\",\"wordorderth_2.xlsx\")\n",
    "rep_n_ran(wordorderen_full, \"ref/wordorderen_full2.xlsx\",\"wordorderen_2.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
